import asyncio
from typing import Any, Dict, List, Optional, Union
from datetime import datetime

from xconnector.adapters.base_adapter import BaseAdapter
from xconnector.interfaces.base_interface import (
    HealthStatus, HealthCheckResult, Capability
)
from xconnector.utils.xconnector_logging import get_logger

logger = get_logger(__name__)


class LMCacheAdapter(BaseAdapter):
    """
    LMCacheé€‚é…å™¨ - ä¿®å¤ç‰ˆ

    æ”¯æŒvLLMå†…ç½®çš„LMCacheè¿æ¥å™¨
    """

    __version__ = "1.0.1"
    __author__ = "xiaoyaolfc"
    __dependencies__ = ["lmcache", "vllm"]

    def __init__(self, core_instance=None, config: Dict[str, Any] = None):
        super().__init__(core_instance, config)

        # æ£€æµ‹SDKæ¨¡å¼
        self.sdk_mode = core_instance is not None and hasattr(core_instance, 'sdk_mode')

        # LMCache connectorå®ä¾‹
        self.lmcache_connector = None
        self.connector_class = None

        # ç®€å•ç»Ÿè®¡
        self.total_requests = 0
        self.cache_hits = 0

        logger.info(f"LMCacheAdapter (Fixed) initialized (SDK mode: {self.sdk_mode})")

    def _find_lmcache_connector(self):
        """æ™ºèƒ½æŸ¥æ‰¾LMCacheè¿æ¥å™¨ç±»"""
        try:
            # åŸºäºä¹‹å‰çš„æµ‹è¯•ç»“æœï¼Œæˆ‘ä»¬çŸ¥é“æ­£ç¡®çš„å¯¼å…¥è·¯å¾„
            try:
                logger.debug("å°è¯•å¯¼å…¥vLLMçš„LMCacheConnector...")
                from vllm.distributed.kv_transfer.kv_connector.lmcache_connector import LMCacheConnector
                logger.info("âœ… æˆåŠŸæ‰¾åˆ°vLLMçš„LMCacheConnector")
                return LMCacheConnector

            except ImportError as e:
                logger.debug(f"vLLM LMCacheConnectorå¯¼å…¥å¤±è´¥: {e}")

            # å…¶ä»–å¤‡ç”¨è·¯å¾„
            backup_attempts = [
                ("lmcache_connector", "LMCacheConnector"),
                ("lmcache.integration.vllm.lmcache_connector", "LMCacheConnector"),
            ]

            for module_path, class_name in backup_attempts:
                try:
                    logger.debug(f"å°è¯•å¤‡ç”¨è·¯å¾„: {module_path}.{class_name}")
                    import importlib
                    module = importlib.import_module(module_path)

                    if hasattr(module, class_name):
                        connector_class = getattr(module, class_name)
                        logger.info(f"âœ… æ‰¾åˆ°å¤‡ç”¨LMCacheè¿æ¥å™¨: {module_path}.{class_name}")
                        return connector_class

                except ImportError:
                    continue
                except Exception as e:
                    logger.debug(f"å¤‡ç”¨è·¯å¾„é”™è¯¯ {module_path}: {e}")
                    continue

            logger.warning("æœªæ‰¾åˆ°ä»»ä½•LMCacheè¿æ¥å™¨å®ç°")
            return None

        except Exception as e:
            logger.error(f"æŸ¥æ‰¾LMCacheè¿æ¥å™¨æ—¶å‡ºé”™: {e}")
            return None

    async def _initialize_impl(self) -> bool:
        """åˆå§‹åŒ–LMCache connector"""
        try:
            # æŸ¥æ‰¾LMCacheè¿æ¥å™¨ç±»
            self.connector_class = self._find_lmcache_connector()

            if self.connector_class:
                logger.info("âœ… LMCache connector class found, ready for initialization")
                return True
            else:
                logger.warning("âŒ No LMCache connector found, using mock implementation")
                self.lmcache_connector = MockLMCacheConnector()
                return True

        except Exception as e:
            logger.error(f"LMCache initialization failed: {e}")
            # å›é€€åˆ°Mockå®ç°
            self.lmcache_connector = MockLMCacheConnector()
            return True

    async def _start_impl(self) -> bool:
        """å¯åŠ¨é€‚é…å™¨"""
        if self.connector_class and not self.lmcache_connector:
            logger.info("LMCache connector class available, waiting for vLLM config")

        # SDKæ¨¡å¼ä¸‹æ³¨å†Œåˆ°VLLMé€‚é…å™¨
        if self.sdk_mode and self.core:
            vllm_adapter = self._get_vllm_adapter()
            if vllm_adapter and hasattr(vllm_adapter, 'register_cache_adapter'):
                vllm_adapter.register_cache_adapter(self)
                logger.info("Registered with vLLM adapter")

        return True

    async def _stop_impl(self) -> bool:
        """åœæ­¢é€‚é…å™¨"""
        if self.lmcache_connector and hasattr(self.lmcache_connector, 'close'):
            try:
                self.lmcache_connector.close()
                logger.info("LMCache connector closed")
            except Exception as e:
                logger.warning(f"Error closing LMCache connector: {e}")
        return True

    # === KVç¼“å­˜æ“ä½œ ===

    async def retrieve_kv(self, model_input: Any, kv_caches: List) -> Dict[str, Any]:
        """æ£€ç´¢KVç¼“å­˜"""
        self.total_requests += 1

        if not self.lmcache_connector:
            return {"found": False, "reason": "No connector"}

        try:
            # è°ƒç”¨LMCache connectorçš„æ–¹æ³•
            result = self.lmcache_connector.recv_kv_caches_and_hidden_states(
                None, model_input, kv_caches
            )

            if result and len(result) >= 2:
                hidden_states, cache_hit = result[0], result[1]
                updated_input = result[2] if len(result) > 2 else model_input

                if cache_hit:
                    self.cache_hits += 1
                    logger.debug("Cache hit!")
                    return {
                        "found": True,
                        "hidden_states": hidden_states,
                        "updated_input": updated_input
                    }
                else:
                    logger.debug("Cache miss")

            return {"found": False}

        except Exception as e:
            logger.debug(f"Cache retrieval failed: {e}")
            return {"found": False, "error": str(e)}

    async def store_kv(self, model_input: Any, kv_caches: List,
                       hidden_states: Any, metadata: Optional[Dict] = None) -> bool:
        """å­˜å‚¨KVç¼“å­˜"""
        if not self.lmcache_connector:
            return False

        try:
            # è°ƒç”¨LMCache connectorçš„æ–¹æ³•
            self.lmcache_connector.send_kv_caches_and_hidden_states(
                None, model_input, kv_caches, hidden_states
            )
            logger.debug("Cache stored successfully")
            return True

        except Exception as e:
            logger.debug(f"Cache storage failed: {e}")
            return False

    async def cleanup_finished(self, request_ids: List[str]) -> int:
        """æ¸…ç†å®Œæˆçš„è¯·æ±‚"""
        return len(request_ids)

    # === é…ç½®æ›´æ–°ï¼ˆé‡è¦ï¼ï¼‰ ===

    def update_cache_config(self, vllm_config: Dict[str, Any]) -> bool:
        """ä»vLLMé…ç½®æ›´æ–°å¹¶åˆ›å»ºLMCache connector"""
        try:
            if not vllm_config:
                logger.warning("No vLLM config provided")
                return False

            if not self.connector_class:
                logger.warning("No LMCache connector class available")
                return False

            # å¦‚æœå·²ç»æœ‰connectorï¼Œå…ˆå…³é—­
            if self.lmcache_connector and hasattr(self.lmcache_connector, 'close'):
                self.lmcache_connector.close()

            # æ¨¡æ‹ŸvLLM configç»“æ„
            class MockVllmConfig:
                def __init__(self, config_dict):
                    self.model_config = config_dict.get('model_config')
                    self.parallel_config = config_dict.get('parallel_config')
                    self.cache_config = config_dict.get('cache_config')
                    self.kv_transfer_config = config_dict.get('kv_transfer_config', {})

            mock_config = MockVllmConfig(vllm_config)

            # åˆ›å»ºLMCache connectorå®ä¾‹
            try:
                # å°è¯•è·å–world_groupï¼Œå¦‚æœæ²¡æœ‰å°±åˆ›å»ºé»˜è®¤çš„
                import torch.distributed as dist
                if dist.is_initialized():
                    world_group = dist.group.WORLD
                else:
                    world_group = None
            except:
                world_group = None

            self.lmcache_connector = self.connector_class(
                rank=0,
                local_rank=0,
                config=mock_config,
                world_group=world_group  # æ·»åŠ ç¼ºå¤±çš„å‚æ•°
            )

            logger.info(f"ğŸ‰ çœŸå®çš„LMCache connectoråˆ›å»ºæˆåŠŸ: {type(self.lmcache_connector).__name__}")
            return True

        except Exception as e:
            logger.error(f"Failed to create LMCache connector: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯: {e.__class__.__name__}: {e}")
            # å›é€€åˆ°mockå®ç°
            self.lmcache_connector = MockLMCacheConnector()
            logger.warning("å›é€€åˆ°Mockå®ç°")
            return False

    def _get_vllm_adapter(self):
        """è·å–VLLMé€‚é…å™¨å¼•ç”¨"""
        if not self.core:
            return None

        # å°è¯•è·å–VLLMé€‚é…å™¨
        for name, adapter in getattr(self.core, 'inference_adapters', {}).items():
            if 'vllm' in name.lower():
                return adapter

        return None

    # === ç»Ÿè®¡æ–¹æ³• ===

    def get_cache_statistics(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        hit_rate = (self.cache_hits / max(self.total_requests, 1)) * 100

        is_real_connector = (
                self.lmcache_connector is not None and
                not isinstance(self.lmcache_connector, MockLMCacheConnector)
        )

        return {
            "total_requests": self.total_requests,
            "cache_hits": self.cache_hits,
            "hit_rate": f"{hit_rate:.2f}%",
            "connector_type": type(self.lmcache_connector).__name__ if self.lmcache_connector else "None",
            "connector_class_available": self.connector_class is not None,
            "real_connector": is_real_connector,
            "connector_module": self.lmcache_connector.__class__.__module__ if self.lmcache_connector else "None"
        }


class MockLMCacheConnector:
    """Mock LMCache connector for fallback"""

    def recv_kv_caches_and_hidden_states(self, model_executable, model_input, kv_caches):
        # æ€»æ˜¯è¿”å›cache miss
        return None, False, model_input

    def send_kv_caches_and_hidden_states(self, model_executable, model_input, kv_caches, hidden_states):
        # Mockå­˜å‚¨ï¼Œä»€ä¹ˆéƒ½ä¸åš
        pass

    def close(self):
        pass