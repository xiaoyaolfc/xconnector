# XConnector configuration for AI-Dynamo integration
# 该代码配置于ai-dynamo/examples/vllm_v0/configs中
XConnectorService:
  # Basic service configuration
  namespace: xconnector
  component_name: xconnector-service

  # Adapter configurations
  adapters:
    # VLLM Adapter
    vllm:
      enabled: true
      class_path: "xconnector.adapters.inference.vllm_adapter.VLLMAdapter"
      config:
        model_name: "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
        tensor_parallel_size: 1
        pipeline_parallel_size: 1
        max_batch_size: 256
        kv_cache_dtype: "auto"
        enable_prefix_caching: true
        enable_chunked_prefill: false

    # LMCache Adapter
    lmcache:
      enabled: true
      class_path: "xconnector.adapters.cache.lmcache_adapter.LMCacheAdapter"
      config:
        storage_backend: "local"
        max_cache_size: 2048  # MB
        enable_compression: true
        cache_config:
          block_size: 16
          num_gpu_blocks: 1000
          num_cpu_blocks: 1000

    # Dynamo Adapter
    dynamo:
      enabled: true
      class_path: "xconnector.adapters.distributed.dynamo_adapter.DynamoAdapter"
      config:
        namespace: "dynamo"
        component_name: "xconnector"
        routing_policy:
          strategy: "least_loaded"  # Options: least_loaded, round_robin, affinity
          affinity_key: "session_id"
          max_requests_per_worker: 100
          health_check_interval: 30
          unhealthy_threshold: 3

  # Routing configuration
  routing:
    # Default routing rules
    rules:
      - source_type: "inference"
        target_type: "cache"
        enabled: true
        priority: 1
        timeout: 30.0
        retry_count: 2
        circuit_breaker_enabled: true

      - source_type: "cache"
        target_type: "inference"
        enabled: true
        priority: 1
        timeout: 30.0

      - source_type: "distributed"
        target_type: "inference"
        enabled: true
        priority: 0

    # Load balancing
    load_balancing:
      default_strategy: "round_robin"
      health_based_routing: true
      circuit_breaker:
        failure_threshold: 5
        timeout: 60.0

  # Monitoring configuration
  monitoring:
    metrics_enabled: true
    metrics_port: 9090
    health_check_interval: 30
    log_level: "INFO"

  # Performance tuning
  performance:
    connection_pool_size: 100
    request_timeout: 60.0
    max_concurrent_requests: 1000