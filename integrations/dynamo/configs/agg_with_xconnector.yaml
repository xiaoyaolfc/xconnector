Common:
  model: /data/model/DeepSeek-R1-Distill-Llama-8B  # ğŸ”§ ä½¿ç”¨å°æ¨¡å‹
  block-size: 32                                    # ğŸ”§ å‡å°‘å—å¤§å°èŠ‚çœå†…å­˜
  max-model-len: 8192                              # ğŸ”§ å‡å°‘æœ€å¤§é•¿åº¦

Frontend:
  served_model_name: DeepSeek-R1-Distill-Llama-8B
  endpoint: dynamo.Processor.chat/completions
  port: 8000

Processor:
  router: round-robin
  router-num-threads: 2                            # ğŸ”§ å‡å°‘çº¿ç¨‹æ•°
  common-configs: [model, block-size, max-model-len]

VllmWorker:
  enforce-eager: true
  max-num-batched-tokens: 8192                     # ğŸ”§ å‡å°‘æ‰¹å¤„ç†å¤§å°
  enable-prefix-caching: true                      # âœ… å°æ¨¡å‹å¯ä»¥å¯ç”¨
  gpu-memory-utilization: 0.85                     # ğŸ”§ é€‚åº¦çš„å†…å­˜åˆ©ç”¨ç‡
  max-num-seqs: 8                                  # ğŸ”§ é€‚ä¸­çš„å¹¶å‘æ•°
  ServiceArgs:
    workers: 1
    resources:
      gpu: '8'
  common-configs: [model, block-size, max-model-len]

Planner:
  environment: local
  no-operation: true